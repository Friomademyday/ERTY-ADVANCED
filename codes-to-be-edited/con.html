<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ERTY: The Conversational AI</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        // Set the global Tailwind theme configuration
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        'aurora-blue': '#4F46E5',
                        'aurora-light': '#E0E7FF',
                        'aurora-dark': '#1F2937',
                    },
                    fontFamily: {
                        sans: ['Inter', 'sans-serif'],
                    },
                }
            }
        }
    </script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');
        .chat-bubble-ai {
            border-bottom-left-radius: 0.75rem;
            border-bottom-right-radius: 0.75rem;
            border-top-right-radius: 0.75rem;
            background-color: #E0E7FF; /* aurora-light */
        }
        .chat-bubble-user {
            border-bottom-left-radius: 0.75rem;
            border-bottom-right-radius: 0.75rem;
            border-top-left-radius: 0.75rem;
            background-color: #4F46E5; /* aurora-blue */
        }
        /* Custom scrollbar for chat history */
        #chat-history::-webkit-scrollbar {
            width: 8px;
        }
        #chat-history::-webkit-scrollbar-thumb {
            background: #9CA3AF;
            border-radius: 4px;
        }
        #chat-history::-webkit-scrollbar-track {
            background: #F3F4F6;
        }
    </style>
</head>
<body class="bg-gray-50 min-h-screen flex items-center justify-center font-sans p-4">

    <div id="app" class="w-full max-w-lg bg-white rounded-3xl shadow-2xl flex flex-col h-[80vh] overflow-hidden">
        
        <!-- Header -->
        <header class="bg-aurora-blue p-5 text-white shadow-lg flex items-center justify-between rounded-t-3xl">
            <h1 class="text-2xl font-bold">ERTY AI</h1>
            <div id="status-indicator" class="flex items-center space-x-2">
                <span id="speaking-text" class="text-sm italic">Online</span>
                <span id="status-dot" class="w-3 h-3 bg-green-400 rounded-full animate-pulse"></span>
            </div>
        </header>

        <!-- Chat History -->
        <div id="chat-history" class="flex-1 overflow-y-auto p-4 space-y-4">
            <!-- Initial greeting message -->
        </div>

        <!-- Input Area -->
        <div class="p-4 bg-gray-100 border-t border-gray-200">
            <div id="loading-indicator" class="text-center py-2 text-sm text-gray-500 hidden">
                ERTY is thinking...
            </div>
            <div class="flex space-x-3">
                <input 
                    type="text" 
                    id="user-input" 
                    placeholder="Ask ERTY anything..." 
                    class="flex-1 p-3 border border-gray-300 rounded-xl focus:outline-none focus:ring-2 focus:ring-aurora-blue"
                    onkeydown="if(event.key === 'Enter') document.getElementById('send-button').click()"
                />
                <button 
                    id="send-button" 
                    class="bg-aurora-blue text-white p-3 rounded-xl hover:bg-indigo-600 transition duration-150 shadow-md disabled:bg-gray-400"
                    onclick="handleUserInput()"
                >
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6 transform -rotate-45" fill="none" viewBox="0 0 24 24" stroke="currentColor" stroke-width="2">
                        <path stroke-linecap="round" stroke-linejoin="round" d="M12 19l9 2-9-18-9 18 9-2zm0 0v-8" />
                    </svg>
                </button>
            </div>
            <p id="error-message" class="text-red-500 text-sm mt-2 hidden">An error occurred.</p>
        </div>
    </div>

    <!-- Firebase and API Setup -->
    <script>
        // Mandatory global variables from the Canvas environment
        const appId = typeof __app_id !== 'undefined' ? __app_id : 'default-app-id';
        const apiKey = ""; // API Key is dynamically injected by the environment if needed

        // --- UTILITY FUNCTIONS ---

        // Converts Base64 string to ArrayBuffer
        const base64ToArrayBuffer = (base64) => {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        };

        // Converts PCM audio data into a WAV Blob
        const pcmToWav = (pcmData, sampleRate) => {
            const numChannels = 1;
            const bytesPerSample = 2; // 16-bit PCM

            const buffer = new ArrayBuffer(44 + pcmData.byteLength);
            const view = new DataView(buffer);

            let offset = 0;

            // RIFF chunk descriptor
            writeString('RIFF');
            view.setUint32(offset, 36 + pcmData.byteLength, true); offset += 4;
            writeString('WAVE');

            // FMT sub-chunk
            writeString('fmt ');
            view.setUint32(offset, 16, true); offset += 4; // Sub-chunk size
            view.setUint16(offset, 1, true); offset += 2; // Audio format (1 = PCM)
            view.setUint16(offset, numChannels, true); offset += 2; // Number of channels
            view.setUint32(offset, sampleRate, true); offset += 4; // Sample rate
            view.setUint32(offset, sampleRate * numChannels * bytesPerSample, true); offset += 4; // Byte rate
            view.setUint16(offset, numChannels * bytesPerSample, true); offset += 2; // Block align
            view.setUint16(offset, bytesPerSample * 8, true); offset += 2; // Bits per sample

            // Data sub-chunk
            writeString('data');
            view.setUint32(offset, pcmData.byteLength, true); offset += 4; // Sub-chunk size

            // Write PCM data
            const pcmView = new Int16Array(pcmData);
            for (let i = 0; i < pcmView.length; i++) {
                view.setInt16(offset, pcmView[i], true);
                offset += 2;
            }

            return new Blob([buffer], { type: 'audio/wav' });

            function writeString(s) {
                for (let i = 0; i < s.length; i++) {
                    view.setUint8(offset + i, s.charCodeAt(i));
                }
                offset += s.length;
            }
        };

        // --- CHAT STATE AND UI MANAGEMENT ---
        let chatHistory = [];
        let isProcessing = false;

        const chatHistoryElement = document.getElementById('chat-history');
        const userInputElement = document.getElementById('user-input');
        const sendButton = document.getElementById('send-button');
        const loadingIndicator = document.getElementById('loading-indicator');
        const statusDot = document.getElementById('status-dot');
        const speakingText = document.getElementById('speaking-text');
        const errorMessageElement = document.getElementById('error-message');

        const updateStatus = (status, isSpeaking = false) => {
            speakingText.textContent = status;
            statusDot.classList.toggle('bg-green-400', !isProcessing && !isSpeaking);
            statusDot.classList.toggle('bg-yellow-400', isProcessing && !isSpeaking);
            statusDot.classList.toggle('bg-red-400', isSpeaking);
            statusDot.classList.toggle('animate-pulse', !isSpeaking);
        };

        const setProcessingState = (processing) => {
            isProcessing = processing;
            userInputElement.disabled = processing;
            sendButton.disabled = processing;
            loadingIndicator.classList.toggle('hidden', !processing);
            updateStatus(processing ? 'Thinking...' : 'Online');
        };

        const displayError = (message) => {
            errorMessageElement.textContent = message;
            errorMessageElement.classList.remove('hidden');
            setTimeout(() => errorMessageElement.classList.add('hidden'), 5000);
            updateStatus('Error', false);
            setProcessingState(false);
        };

        const renderMessage = (role, text) => {
            const container = document.createElement('div');
            container.className = `flex ${role === 'user' ? 'justify-end' : 'justify-start'}`;

            const bubble = document.createElement('div');
            bubble.className = `max-w-[80%] p-3 rounded-xl shadow-md ${
                role === 'user'
                    ? 'bg-aurora-blue text-white chat-bubble-user'
                    : 'bg-aurora-light text-aurora-dark chat-bubble-ai'
            }`;
            bubble.textContent = text;
            container.appendChild(bubble);
            chatHistoryElement.appendChild(container);
            
            // Scroll to the latest message
            chatHistoryElement.scrollTop = chatHistoryElement.scrollHeight;
        };
        
        // --- API CALLS ---

        const callGeminiTTS = async (text, retryCount = 0) => {
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;
            const voiceName = "Kore"; // A firm, clear voice

            const payload = {
                contents: [{
                    parts: [{ text: text }]
                }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: voiceName }
                        }
                    }
                },
                model: "gemini-2.5-flash-preview-tts"
            };

            updateStatus('Speaking...', true);

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`TTS API returned status ${response.status}`);
                }

                const result = await response.json();
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType;

                if (!audioData || !mimeType || !mimeType.startsWith("audio/L16")) {
                    throw new Error("Invalid audio response from TTS API.");
                }
                
                // Extract sample rate from mimeType, e.g., audio/L16;rate=24000
                const rateMatch = mimeType.match(/rate=(\d+)/);
                const sampleRate = rateMatch ? parseInt(rateMatch[1], 10) : 24000; 

                const pcmData = base64ToArrayBuffer(audioData);
                const pcm16 = new Int16Array(pcmData);
                const wavBlob = pcmToWav(pcm16, sampleRate);
                const audioUrl = URL.createObjectURL(wavBlob);

                const audio = new Audio(audioUrl);
                
                return new Promise((resolve) => {
                    audio.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                        resolve();
                    };
                    audio.onerror = (e) => {
                        console.error("Audio playback error:", e);
                        URL.revokeObjectURL(audioUrl);
                        resolve(); // Resolve even on error to unblock the UI
                    };
                    audio.play();
                });

            } catch (error) {
                console.error("TTS failed:", error);
                if (retryCount < 3) {
                    const delay = Math.pow(2, retryCount) * 1000;
                    console.log(`Retrying TTS in ${delay}ms...`);
                    await new Promise(r => setTimeout(r, delay));
                    return callGeminiTTS(text, retryCount + 1);
                } else {
                    displayError(`TTS failed after multiple retries. Console log has details.`);
                    throw error;
                }
            }
        };

        const callGeminiLLM = async (retryCount = 0) => {
            const apiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;
            
            // --- UPDATED SYSTEM PROMPT TO INCLUDE FRIO ---
            const systemPrompt = "You are ERTY, a friendly, concise, and highly knowledgeable AI assistant similar to Siri. Your creator is Frio. Keep your responses short and directly answer the user's question.";

            const payload = {
                contents: chatHistory.map(msg => ({ role: msg.role, parts: [{ text: msg.content }] })),
                systemInstruction: {
                    parts: [{ text: systemPrompt }]
                },
                tools: [{ "google_search": {} }],
            };
            
            setProcessingState(true);

            try {
                const response = await fetch(apiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    throw new Error(`LLM API returned status ${response.status}`);
                }

                const result = await response.json();
                const aiText = result.candidates?.[0]?.content?.parts?.[0]?.text;

                if (!aiText) {
                    throw new Error("No text content received from the LLM.");
                }
                
                setProcessingState(false);
                return aiText;

            } catch (error) {
                console.error("LLM failed:", error);
                if (retryCount < 3) {
                    const delay = Math.pow(2, retryCount) * 1000;
                    console.log(`Retrying LLM in ${delay}ms...`);
                    await new Promise(r => setTimeout(r, delay));
                    return callGeminiLLM(retryCount + 1);
                } else {
                    displayError(`Failed to get response from ERTY after multiple retries.`);
                    throw error;
                }
            }
        };

        // --- MAIN APPLICATION LOGIC ---

        const handleUserInput = async () => {
            if (isProcessing) return;

            const userText = userInputElement.value.trim();
            if (userText === "") return;
            
            // 1. Clear input and render user message
            userInputElement.value = '';
            renderMessage('user', userText);

            // 2. Update chat history
            chatHistory.push({ role: 'user', content: userText });

            try {
                // 3. Get LLM response
                const aiResponse = await callGeminiLLM();

                // 4. Update chat history with AI response
                chatHistory.push({ role: 'model', content: aiResponse });

                // 5. Render AI message
                renderMessage('model', aiResponse);

                // 6. Speak the response
                await callGeminiTTS(aiResponse);

            } catch (error) {
                console.error("Fatal chat error:", error);
                // The error display is handled within the API call functions
                renderMessage('model', "I'm sorry, I've encountered a problem and cannot respond right now.");
            } finally {
                setProcessingState(false);
                updateStatus('Online', false);
            }
        };

        const initializeAurora = async () => {
            const initialGreeting = "Hello, I am ERTY. Ask me anything, and I'll speak the answer!";
            
            // Set initial state
            chatHistory.push({ role: 'model', content: initialGreeting });
            renderMessage('model', initialGreeting);

            // Play greeting
            try {
                await callGeminiTTS(initialGreeting);
            } catch (e) {
                console.warn("Initial TTS greeting failed, continuing without audio playback.");
            }
            updateStatus('Online', false);
        };

        // Start the application when the window loads
        window.onload = initializeAurora;
    </script>
</body>
</html>
